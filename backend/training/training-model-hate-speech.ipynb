{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3O65tOoCVYq"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMRt4x9xzC16",
        "outputId": "54d6d41a-50a2-4e13-c4b5-3f7cfc1360d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: sphinx 5.3.0 has requirement docutils<0.20,>=0.14, but you'll have docutils 0.20.1 which is incompatible.\n",
            "WARNING: You are using pip version 20.1.1; however, version 24.0 is available.\n",
            "You should consider upgrading via the 'c:\\users\\rampu\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install indic-nlp-library -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQA0n0Cz1yBO",
        "outputId": "085e0404-549b-427f-cb40-067a6240a910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fasttext_wheel\n",
            "  Downloading fasttext_wheel-0.9.2-cp37-cp37m-win_amd64.whl (225 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\rampu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from fasttext_wheel) (1.21.6)\n",
            "Collecting pybind11>=2.2\n",
            "  Downloading pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\rampu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from fasttext_wheel) (47.1.0)\n",
            "Installing collected packages: pybind11, fasttext-wheel\n",
            "Successfully installed fasttext-wheel-0.9.2 pybind11-2.12.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.1.1; however, version 24.0 is available.\n",
            "You should consider upgrading via the 'c:\\users\\rampu\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext_wheel "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SWhBGqzY1yDi"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "import fasttext.util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_lvCt0u1yFj",
        "outputId": "a9def1b8-8dcb-473a-9220-5b52ad4daf3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ft = fasttext.load_model('C:/sai/projects/major project/flask_app/indicnlp.ft.te.300.bin')\n",
        "ft.get_dimension()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ8RP-Vr1yI9",
        "outputId": "ce5e94f2-4b92-4667-d978-5350e53ddd80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fasttext.util.reduce_model(ft, 50)\n",
        "ft.get_dimension()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VAeTbI6T18yq"
      },
      "outputs": [],
      "source": [
        "from indicnlp.tokenize import indic_tokenize\n",
        "def tokenize_telugu(text):\n",
        "    return indic_tokenize.trivial_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IVbTaFTn181J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load train and validation data\n",
        "train_data = pd.read_csv(\"telugu_train.csv\")\n",
        "val_data = pd.read_csv(\"telugu_val.csv\")\n",
        "test_data = pd.read_csv(\"telugu_test.csv\")\n",
        "\n",
        "# Tokenize the text data\n",
        "train_data['tokens'] = train_data['text'].apply(tokenize_telugu)\n",
        "val_data['tokens'] = val_data['text'].apply(tokenize_telugu)\n",
        "test_data['tokens'] = test_data['text'].apply(tokenize_telugu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iggw1BOS184n"
      },
      "outputs": [],
      "source": [
        "def get_sentence_vector(tokens, model):\n",
        "    # FastText does not have wv attribute, so we use 'get_word_vector'\n",
        "    vectors = [model.get_word_vector(word) for word in tokens]\n",
        "    if not vectors:\n",
        "        return None\n",
        "    return sum(vectors) / len(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply the function to generate word embeddings\n",
        "train_data['embeddings'] = train_data['tokens'].apply(lambda x: get_sentence_vector(x, ft))\n",
        "val_data['embeddings'] = val_data['tokens'].apply(lambda x: get_sentence_vector(x, ft))\n",
        "test_data['embeddings'] = test_data['tokens'].apply(lambda x: get_sentence_vector(x, ft))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gR8f1r_82KIS"
      },
      "outputs": [],
      "source": [
        "X_train = list(train_data['embeddings'])\n",
        "y_train = train_data['label']\n",
        "\n",
        "X_val = list(val_data['embeddings'])\n",
        "y_val = val_data['label']\n",
        "\n",
        "X_test = list(test_data['embeddings'])\n",
        "y_test = test_data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aKTUy_742KLu"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lIkKRg5O2QtO"
      },
      "outputs": [],
      "source": [
        "classifiers = {\n",
        "#     'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "#     'k-NN': KNeighborsClassifier(),\n",
        "#     'Naive Bayes': GaussianNB(),\n",
        "#     'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(random_state=42)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQVTPdng2Qwp",
        "outputId": "7f480079-9c85-4b6e-c1cd-2683ae05562b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training and evaluating SVM...\n",
            "Accuracy on validation set for SVM: 84.52%\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import pickle\n",
        "for name, classifier in classifiers.items():\n",
        "    print(f\"\\nTraining and evaluating {name}...\")\n",
        "    classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    predictions_val = classifier.predict(X_val)\n",
        "\n",
        "    # Evaluate accuracy on the validation set\n",
        "    accuracy_val = accuracy_score(y_val, predictions_val)\n",
        "    print(f\"Accuracy on validation set for {name}: {accuracy_val * 100:.2f}%\")\n",
        "    with open('model.pkl', 'wb') as f:\n",
        "        pickle.dump(classifier, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZBAs86F2WJX",
        "outputId": "c3215279-f846-47c4-f169-1b5f82dd7ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on test set for SVM: 83.63%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate each classifier on the test set\n",
        "for name, classifier in classifiers.items():\n",
        "    # Predict on the test set\n",
        "    predictions_test = classifier.predict(X_test)\n",
        "\n",
        "    # Evaluate accuracy on the test set\n",
        "    accuracy_test = accuracy_score(y_test, predictions_test)\n",
        "    print(f\"\\nAccuracy on test set for {name}: {accuracy_test * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBtYWxa8CP2Z"
      },
      "source": [
        "# Tesing Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6GDaADhGB-AH"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GvEeWVEBC3Rt"
      },
      "outputs": [],
      "source": [
        "text = \"hello world\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "b416DXDIC8JY"
      },
      "outputs": [],
      "source": [
        "text_tokens = tokenize_telugu(text)\n",
        "text_embedding = get_sentence_vector(text_tokens, ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not Abusive\n"
          ]
        }
      ],
      "source": [
        "prediction = model.predict([text_embedding])\n",
        "print(\"Abusive\" if prediction == 0 else \"Not Abusive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8PknLrGD9PI",
        "outputId": "11dd3716-fa52-49c7-f579-416bb40ce745"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.25373834,  0.11429359, -0.46006247,  0.08539951, -0.35152858,\n",
              "        0.41466865, -0.50430715,  0.23304223,  0.28547463,  0.27407438,\n",
              "       -0.06326284,  0.01679939,  0.14189519,  0.27268705,  0.07280811,\n",
              "       -0.33512124, -0.26886582, -0.13984728, -0.25157177,  0.509647  ,\n",
              "        0.06752215,  0.22076799, -0.09672558,  0.24390587,  0.12136319,\n",
              "       -0.1530877 , -0.0298101 , -0.16665901, -0.3009723 , -0.03589639,\n",
              "        0.13174278, -0.08748925, -0.04589874,  0.0035856 , -0.1692615 ,\n",
              "       -0.1627296 ,  0.09659679, -0.01322322,  0.00985536,  0.10169964,\n",
              "        0.05615437, -0.1327372 ,  0.00719264, -0.07197587, -0.10012716,\n",
              "       -0.05117296,  0.02871909,  0.03819418,  0.23590522, -0.17053461],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_embedding"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
